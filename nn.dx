' (Start)

' Create some data

-- want to learn the parameters of w1 b1 w2 b2


-- 1 - get gradient of forward
-- 2 - loop
-- 3 - state in order to update


instance pairAdd : Add a ?=> Add b ?=> Add (a & b) where
  add = \(a, b) (a', b'). (a + a', b + b')
  sub = \(a, b) (a', b'). (a - a', b - b')
  zero = (zero, zero)

@instance pairVS : VSpace a ?=> VSpace b ?=> VSpace (a & b) =
    MkVSpace pairAdd (\ s (a', b'). (s .* a', s .* b'))


grid: ((Fin 10) & (Fin 10)) => (Float & Float)  =
   for (i, j).
       (IToF (ordinal i), IToF (ordinal j))

x = grid
y = for i.
   select ((fst x.i) > 3.0) 1 0 

def to_vec ((a, b):(Float & Float)) : (Fin 2) => Float =
    [a, b]

:plot grid


' Neural network

def WnB (a:Type) (b:Type) : Type  =
   (a => b => Float &
    b => Float)


def relu (input : Float) : Float =
  select (input > 0.0) input 0.0

def linear_layer (input : h => Float)
                 ((weight, bias): WnB h h2)
                   : h2 => Float =
    for i : h2.
       bias.i + sum for j : h. weight.j.i * input.j
    

' Initialization

key = (newKey 0)

' Weights and biases

def initWnB (key: Key) : WnB in out =
  (k1, k2) = splitKey key
  ((for i j. rand (ixkey2 k1 i j)),
   (for i. rand (ixkey k2 i)))

def Parameters (in : Type) (h2 : Type) (class: Type) : Type =
  (WnB in h2 & WnB h2 class)

' Declare the size of the network

Params = Parameters (Fin 2) (Fin 10) (Fin 2)

(k1, k2) = splitKey key
params : Params = (initWnB k1, initWnB k2)

:t params
  
' Type of the parameters

def forward
    ((wnb1, wnb2) : Parameters h h2 class) 
    (input : (h => Float))
    (target: Int32)
      : Float = 
  out1 = linear_layer input wnb1
  out2 = for j. relu out1.j
  out3 = linear_layer out2 wnb2
  (logsoftmax out3).(target@class)

def loss (params : Params) : Float =
  -mean for i. forward params (to_vec x.i) y.i 

' SGD

rate = 0.003
loop = withState params \ paramsRef.
  for i : (Fin 100).
      eloss: Float  = loss (get paramsRef)
      grads : Params  = (grad loss) (get paramsRef)
      paramsRef := (get paramsRef)  - rate .* grads
      eloss

epochloss = (fst loop)
epoch  = for i : (Fin 100). IToF (ordinal i)
:t epochloss

:plot zip epoch epochloss 



 


